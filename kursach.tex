\documentclass[a4paper]{article}

\usepackage{fullpage} % Package to use full page
\usepackage{parskip} % Package to tweak paragraph skipping
\usepackage{tikz} % Package for drawing
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{float}
\usepackage{mathtools}
\usepackage{ragged2e}
\usepackage{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[ukrainian, english]{babel}
\renewcommand{\baselinestretch}{1.5}
\usepackage[T2A]{fontenc}
\usepackage[figurename=Рис.]{caption}
\usepackage[tablename=Табл.]{caption}
\renewcommand{\refname}{Література}
\addto\captionsenglish{\renewcommand{\refname}{Література}}
\addto\captionsenglish{\renewcommand{\contentsname}{Зміст}}
\renewcommand{\contentsname}{Зміст}
\newcommand\tab[1][1cm]{\hspace*{#1}}
\newcommand\norm[1]{\left\lVert#1\right\rVert}
\title{Метод скінченних елементів}
\author{Прохоров Олександр}
\date{2016}
\graphicspath{ {images/} }
\numberwithin{equation}{section}


\begin{document}
\hfill
\tableofcontents
\newpage
\section{Вступ}
Метод скінченних елементів (МСЕ) є одним з найпоширеніших методів числового розв’язування крайових задач математичної фізики. Його застосовують для розв’язування складних рiвнянь теорiї пружностi та механiки суцiльних середовищ. Процес розв’язування побудований на повному усуненні диференціального рівняння або на розкладі диференціального рівняння в часткових похід\-них в апроксимуючу систему звичайних диференціальних рівнянь.
В даній роботі розглянемо постановки крайової задачі, двоїстої до неї задачі та комплексну похибку обох задач за умови розв'язку на одній і тій же сітці.
Для розв’язування диференці\-ального рівняння використаємо метод Гальоркіна, що наближує розв’язок крайової задачі. Для покращення розв’язку будемо використовувати стратегію адаптування сітки, за допомогою апосте\-ріорного оцінювача будемо знаходити проблемні скінченні елементи. Ефективність методу покаже\-мо числовими розв’язками поставлених задач.

\section{Формулювання крайової задачі}
Розглянемо постановку крайової задачі. Необхідно знайти таку функцію $u=u(x)$ таку, що є розв’язком рівняння
\begin{equation}\label{boundaryEquation}
L[u]=f
\end{equation}
де
\begin{equation}\label{differentialOperator}
L[u]=-(\mu(x)u')'+\beta(x)u'+\sigma(x)u
\end{equation}
і задовольняє таким крайовим умовам
\begin{equation}\label{boundaryCondition}
\begin{split}
u(a)=0,\\
-\mu(b)u'(b)=\alpha[u(b)-\bar{u}].
\end{split}
\end{equation}
Тут $\mu(x)>0, \beta=\beta(x), \sigma=\sigma(x),f=f(x)$ - задані функції\\
$\alpha, \bar{u}$ - деякі сталі.
\begin{equation}
\mu \in H^1, \beta, \sigma, f\in H^0
\end{equation}
Крайова задача \ref{boundaryEquation} сформульована за допомогою лiнiйного оператора диференцiювання, який визначається у виглядi \ref{differentialOperator}.

\section{Варіаційна постановка задачі}
Знайдемо скалярний добуток лівої і правої частини рівняння з $ v \in H^1, v(a) = 0 $, де скалярний добуток має вигляд $ (u, v) = \int_a^b u(x)v(x)dx $. Тоді:
\begin{equation}
\int_a^b [-(\mu(x)u'(x))'v(x) + \beta(x)u'(x)v(x) + \sigma(x)u(x)v(x)]dx = \int_a^b f(x)v(x)dx
\end{equation}
Проінтегруємо частинами перший доданок інтегралу
\begin{equation}
-\mu(x)u'(x)v(x)\Bigr|_a^b + \int_a^b [\mu(x)u'(x)v'(x) + \beta(x)u'(x)v(x) + \sigma(x)u(x)v(x)]dx = \int_a^bf(x)v(x)dx
\end{equation}
\begin{equation}
\begin{split}
& \int_a^b [\mu(x)u'(x)v'(x) + \beta(x)u'(x)v(x) + \sigma(x)u(x)v(x)]dx \\&  - \mu(b)u'(b)v(b) + \mu(a)u'(a)v(a) = \int_a^bf(x)v(x)dx
\end{split}
\end{equation}
З умов $ v(a) = 0, -\mu(b)u'(b) = \alpha(u(b) - \bar{u}) $:
\begin{equation}
\int_a^b [\mu(x)u'(x)v'(x) + \beta(x)u'(x)v(x) + \sigma(x)u(x)v(x)]dx + \alpha u(a)v(a) = \int_a^bf(x)v(x)dx + \alpha\bar{u}v(a)
\end{equation}
Звідси запишемо білінійну форму $ a(u,v) $ і функціонал $ <l,v> $
\begin{equation}\label{variationalBilinearForm}
a(u, v) = \int_a^b [\mu(x)u'(x)v'(x) + \beta(x)u'(x)v(x) + \sigma(x)u(x)v(x)]dx + \alpha u(a)v(a)
\end{equation}
\begin{equation}\label{variationalFunctional}
<l,v> = \int_a^bf(x)v(x)dx + \alpha\bar{u}v(a)
\end{equation}
Тоді варіаційна постановка задачі матиме вигляд 
\begin{equation}\label{variationalProblem}
\begin{split}
& ? u \in H^1,
\\& a(u,v) = <l,v>, \forall v \in H^1, v(a) = 0
\end{split}
\end{equation}

Побудуємо еквівалентну задачу, яка матиме вигляд:
\begin{equation}\label{equivalentProblem}
\begin{split}
& ? u \in H^1
\\ & J(u) = \min_{ \forall v \in H^1, v(a)=0}J(v)
\end{split}
\end{equation}
де
\begin{equation}\label{equivalentEquation}
J(v) = a(u,v) - 2<l,v>
\end{equation}

\section{Побудова наближеного розв’язку}
Шукатимемо розв’язок \ref{boundaryEquation} у вигляді 
\begin{equation}\label{uhDefinition}
u_h(x)\approx\sum_{i=0}^{N} c_i\phi_i(x)
\end{equation}
де $\phi_i\in\{\phi_k\}_{k=0}^{k=N} \subset H^1. \{\phi_k\}_{k=0}^{k=N}$ - система базисних функцій розмірності N у просторі $H^1$. Підставимо $u_h$ як $u$ і $\phi_i$ як $v$ в \ref{variationalProblem}.
Отримаємо неоднорiдну систему лiнiйних алгебраїчних рiвнянь:
\begin{equation}
a(u_h, \phi_k)=<l,\phi_k>,  k=0..N
\end{equation}
\begin{equation}\label{matrixEquation}
\sum_{i=0}^{N} c_iA_{ki} = B_k,  k=0..N
\end{equation}
де
\begin{equation}\label{AkiLast}
\begin{split}
A_{ki}= \int_a^b \beta(x) \phi_i'(x) \phi_k(x) dx+
\int_a^b \sigma(x) \phi_i(x) \phi_k(x) dx + \alpha \phi_i(b) \phi_k(b)  
\end{split}
\end{equation}
\begin{equation}\label{BkLast}
B_k=\int_a^bf(x)\phi_k(x)dx + \alpha \phi_k(b) \bar{u}
\end{equation}
\begin{eqnarray}\label{equationsSystem}
\begin{bmatrix}
A_{00} & A_{01} & \cdots & A_{0N} \\
A_{10} & A_{11} & \cdots & A_{1N} \\
\vdots & \vdots & \ddots & \vdots \\
A_{N0} & A_{N1} & \cdots & A_{NN} \\
\end{bmatrix}
\begin{bmatrix}
c_0 \\
c_1 \\
\vdots \\
c_N \\
\end{bmatrix}
=
\begin{bmatrix}
B_0 \\
B_1 \\
\vdots \\
B_N \\
\end{bmatrix}
\end{eqnarray}
Розв’язавши дану систему рiвнянь отримаємо набiр коефiцiєнтiв, за допомогою яких складемо лiнiйну комбiнацiю \ref{uhDefinition}
\section{Вибір базисних функцій}
Зафіксуємо натуральне N i подiлимо вiдрiзок [a,b] на скiнченнi елементи з кроком $h=\frac{b-a}{N}$ таким чином, щоб $x_0 = a < x_1 < \ldots < x_{N-1} < x_N = b$. З наведених вище мiркувань отримаємо наступнi обмеження для системи базисних функцiй:
\begin{enumerate}
\item $\phi_i \in H^1([a, b]), i = 0, 1\ldots$
\item Для будь-якого скiнченного N система функцiй $\phi_0, \phi_1, \ldots, \phi_N$ лiнiйно незалежна на [a,b].
\item Функцiї $\phi_i, i=0,1,\ldots $ утворюють у класi $H^1([a, b])$ повну систему.
\end{enumerate}
Виберемо в якості базисних фукцій функції Куранта(кусково-лінійні поліноми першого порядку). Подамо їх в наступному вигляді:
\begin{equation}\label{courantDefinition}
\phi_i(x)=
\begin{cases} 
0, & a\leq x < x_{i-1}\\ \frac{x-x_{i-1}}{h}, & x_{i-1} < x \leq x_i\\ 
\frac{x_{i+1} - x}{h}, & x_i < x \leq x_{i+1} \\
0, & x_{i+1} < x \leq b
\end{cases}
,i=0,\ldots,N
\end{equation}
$\phi_i \in V \subset H^1([a, b]), dimV = N$. V пiдпростiр простору Соболєва в якому ми вибрали систему базисних функцiй. Якщо вибрати систему базисних функцiй таким чином, ми отримаємо тридiа\-гональну матрицю. Аналiзуючи \ref{courantDefinition} можна побачити, що iнтеграли \ref{AkiLast}, \ref{BkLast} є сенс рахувати лише на вiдповiдних скiнченних елементах.

\section{Апостеріорний оцінювач похибок}
Розглянемо наступну кусково-лінійну функцію:
\begin{equation}\label{bubbleFunctions}
b_i(x)=\begin{cases}
\frac{ x - x_i } { x_{i + \frac{1}{2} } - x_i } & \forall x \in [x_i, x_{i + \frac{1}{2}}] \\
\frac{ x_{i + 1} - x} { x_{ i + 1 } - x_{ i + \frac{1}{2} } } & \forall x \in [ x_{ i + \frac{1}{2} }, x_i] \\
\end{cases}
\end{equation}
Тут $x_{ i + \frac{1}{2} } = \frac{x_{ i + 1 } + x_i}{2}$ Шукатимемо наближення $\epsilon_h(x) \in E$ до справжньої похибки наближення $e_h~=~u-u_h$ у вигляді лінійної комбінації:
\begin{equation}
e_h(x)\approx\epsilon_h(x)=\sum_{i=0}^{N-1}\lambda_ib_i(x).
\end{equation}
Тут $\{\lambda_i\}_{i=0}^{N-1}$ - невідомі коефіцієнти. Аналогічно отримаємо схему Гальоркіна \ref{equationsSystem}, але з іншими коефцієнтами:

\begin{eqnarray}
\begin{bmatrix}
E_{00} & 0 & \cdots & 0 \\
0 & E_{11} & \cdots & 0 \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots & E_{N-1N-1} \\
\end{bmatrix}
\begin{bmatrix}
\lambda_0 \\
\lambda_1 \\
\vdots \\
\lambda_{N-1} \\
\end{bmatrix}
=
\begin{bmatrix}
F_0 \\
F_1 \\
\vdots \\
F_{N-1} \\
\end{bmatrix}
\end{eqnarray}
де
\begin{equation}\label{Ei}
\begin{split}
E_i = ||b_i||^2 = & \int_a^b p'(x)b_i'(x)b_i(x)dx + \int_a^b p(x)b_i'(x)b_i'(x)dx + \int_a^b q(x)b_i'(x)b_i(x)dx + \\ & \int_a^b r(x)b_i(x)b_i(x)dx - p(b)b_i'(b)b_i(b) + p(a)b_i'(a)b_i(a)
\end{split}
\end{equation}
\begin{equation}\label{Fi}
\begin{split}
F_i=& <\rho(u_h),b_i>=\int_a^b f(x)b_i(x)dx-\int_a^b p'(x)u_h'(x)b_i(x)dx - \int_a^b p(x)u_h'(x)b_i'(x)dx - \\ & \int_a^b q(x)u_h'(x)b_i(x)dx - \int_a^b r(x)u_h(x)b_i(x)dx + p(b)u_h'(b)b_i(b) - p(a)u_h'(a)b_i(a)
\end{split}
\end{equation}
Коефіцієнти \ref{Ei}, \ref{Fi} отриманi шляхом замiни $u = e + u_h$ та $\phi_i = b_i$ у попереднiх кроках. Завдяки бабл-функцiї \ref{bubbleFunctions} ми отримали дiагональну проблему, з якої можна легко визначити коефiцiєнти $\lambda_i$
\begin{equation}
\lambda_i = \frac{<\rho(u_h), b_i>}{\norm{b_i}^2}
\end{equation}
\begin{equation}
\norm{e_h}^2\approx\norm{\epsilon_h}^2=\norm{\sum_{i=1}^{N-1}\lambda_ib_i}^2 = \sum_{i=1}^{N-1}\lambda_i^2\norm{b_i}^2
\end{equation}
Як бачимо з наведених міркувань, обрані базисні функції суттєво спрощують кількість обчислень для визначення похибки на кожному скінченному елементі сітки. Це може бути зручно при проектуваннi адаптивних схем МСЕ для задач бiльшої вимiрностi, де потреба локалiзацiї проблем\-них елементiв, набагато вища.

\section{Стратегія адаптування сітки}
Наведені вище вирази дають змогу побудувати рекурсивний алгоритм з допомогою якого можна згущувати сітку в місцях, де апостеріорний оцінювач визначив похибку, яка перевищує бажану точність. Таким чином на кожному скінченному елементі може бути гарантована довільна наперед задана точність. Індикатори згущення сітки визначаються таким чином:
\begin{equation}\label{error}
\eta_i=\frac{\norm{\epsilon_h}_i}{\sqrt{ \frac{1}{N} \sum_{j=0}^{N-1}(\norm{u_h}_j^2 + \norm{e_h}_j^2)}}100\%=\frac{\sqrt{N}\norm{\epsilon_h}_i} {\norm{u_h}_V^2 + \norm{e_h}_V^2} 100\%
\end{equation}
де
\begin{equation}
\norm{u_h}_i^2=\int_{x_i}^{x_{i+1}}[u_h']^2dx, u=0,\ldots, N-1
\end{equation}
Наведений вираз \ref{error} визначає, який вiдсоток становить норма похибки вiд середнього значення норми розв’язку на кожному скiнченному елементi. Якщо це число бiльше вiд заданого допустимого рiвня похибки, то цей скiнченний елемент подiляють на два новi шляхом додавання нового вузла сiтки в його центр ваги[1]. Коли ж iндикатор похибки певного скiнченного елемента не перевищує допустимого рiвня, то такий елемент без змiн входитиме до нової розрахункової сiтки. Процес згущення сітки скніченних елементів завершується за умови, що на даному кроці адаптації не було додано жодного нового вузла.
Дана стратегія дозволяє отримати розв'язок з бажаною точністю на мінімально можливій сітці.

\section{Формулювання двоїстої задача}
Двоїстою до даної називають задачу, шуканим розв'язком якої


\section{Аналiз числових результатiв}
Проведемо кілька експериментів для запропонованої схеми МСЕ і проілюструємо результати.\\
\textbf{Приклад 1.} Виберемо наступну крайову задачу:
$-u'' + 3000(\frac{2}{3} - x)u' + u'=3000, u(0)=u(1)=0$\\
Початкову сітку виберемо з 2 елементів, продемонструємо апроксимацiї розв’язку при рiзних значен\-нях N на прикладi МСЕ та адаптивного h-методу.\\
На рис.1 показано результат апроксимації використовуючи адаптивний метод згущення сітки. Апроксимація обчислена з допустимою похибкою $\delta=10\%$. Трикутниками видiлено значення у вузлах остаточної сiтки iз 36-елементiв.
\begin{figure}[H]
\includegraphics[width=\textwidth]{figure_3.png}
\caption{Апроксимація адаптивним методом}
\end{figure}
\begin{figure}[H]
\includegraphics[width=\textwidth]{figure_4.png}
\caption{Графік двоїстої функції}
\end{figure}
Табл. 1 мiстить характеристики апроксимацiї для рiвномiрно розподiленої сiтки. Як бачимо, зi збiльшенням кiлькостi елементiв $\norm{u_h}_H \to \norm{u}_H$, а $\norm{e_h}_H \to 0$. Тут
\begin{equation}
p=\ln{\frac{\norm{e_h}_{i-1}}{\norm{u_h}_i}}/\ln{\frac{N_i}{N_{i-1}}}
\end{equation}

\begin{table}[H]
\centering
\begin{tabular}{|l|l|l|l|l|l|l|l|}
\hline
N   & $ ||u_h||_V^2 $ & $ ||e_h||_V^2 $ & $ \frac{||e_h||_V}{||u_h||_V}, \% $ & $ p $ & $ ||\phi_h||^2 $ & $ ||f||^2 - ||u_h||^2 - ||\phi_h||^2 $ & $ \sqrt{\frac{||f||^2 - ||u_h||^2 - ||\phi_h||^2}{||u_h||^2 + ||\phi_h||^2}} $ \\ \hline
10 & 3041.9 & 4228.6 & 117.9 &  & 2.1305e+04 & 8.9757e+06 & 1920.0 \\ \hline
20 & 2976.9 & 211.56 & 26.658 & 2.316 & 2.8704e+04 & 8.9683e+06 & 1682.5 \\ \hline
40 & 2995.1 & 10.294 & 5.8627 & 2.2591 & 1.0944e+04 & 8.9861e+06 & 2539.1 \\ \hline
80 & 2994.7 & 2.3565 & 2.8052 & 1.0827 & 1.311e+04 & 8.9839e+06 & 2361.9 \\ \hline
160 & 2994.5 & 0.58504 & 1.3977 & 1.0141 & 1.3555e+04 & 8.9835e+06 & 2329.8 \\ \hline

\end{tabular}
\caption{Характеристики апроксимацiї на рівномірній сiтцi.}
\end{table}

Табл. 2 мiстить характеристики апроксимацiї для адаптивної сiтки. Можна зауважити, що на кожному кроцi N, ми отримуємо кращi значення, оскiльки значення похибки апроксимацiї зменшу\-ється. Порiвнюючи з рiвномiрно розподiленою сiткою можна побачити, що при меншiй кiлькостi елементiв ми отримаємо кращi значення апроксимацiї.

\begin{table}[H]
\centering
\begin{tabular}{|l|l|l|l|l|l|l|}
\hline
N   & $ ||u_h||_V^2 $ & $ ||e_h||_V^2 $ & $ \frac{||e_h||_V}{||u_h||_V}, \% $ & $ ||\phi_h||^2 $ & $ ||f||^2 - ||u_h||^2 - ||\phi_h||^2 $ & $ \sqrt{\frac{||f||^2 - ||u_h||^2 - ||\phi_h||^2}{||u_h||^2 + ||\phi_h||^2}} \% $ \\ \hline
2 & 4461.3 & 5319.2 & 109.19  & 3.5845e+04 & 8.9597e+06 & 1490.9 \\ \hline
4 & 3326.6 & 4301.9 & 113.72  & 2.0248e+04 & 8.9764e+06 & 1951.3 \\ \hline
8 & 3277.6 & 5989.5 & 135.18  & 5.9135e+04 & 8.9376e+06 & 1196.7 \\ \hline
16 & 2998.6 & 1297.2 & 65.774 & 2.0305e+04 & 8.9767e+06 & 1962.7 \\ \hline
32 & 2993.6 & 19.329 & 8.0355 & 1.3464e+04 & 8.9835e+06 & 2336.4 \\ \hline
35 & 2996.8 & 4.3792 & 3.8227 & 1.3199e+04 & 8.9838e+06 & 2355.2 \\ \hline
36 & 2996.8 & 2.8239 & 3.0697 & 1.3199e+04 & 8.9838e+06 & 2355.2 \\ \hline

\end{tabular}
\caption{Характеристики апроксимацiї на рівномірній сiтцi.}
\end{table}

\textbf{Приклад 2.} Виберемо наступну крайову задачу:
$-u'' + u_x'+u=(1 + \pi^2)\sin(\pi x) + \pi \cos(\pi x), u(0)=0, -u'(1) = (u(1) + \pi)$\\
Її точним розв'язком є функція $ u(x) = \sin(\pi x) $
На рис.2 показано результат апроксимації використовуючи адаптивний метод згущення сітки. Апроксимація обчислена з допустимою похибкою $\delta=5\%$. Трикутниками видiлено значення у вузлах остаточної сiтки iз 22-елементiв.

\begin{figure}[H]
\includegraphics[width=\textwidth]{figure_5.png}
\caption{Апроксимація адаптивним методом}
\end{figure}

\begin{figure}[H]
\includegraphics[width=\textwidth]{figure_6.png}
\caption{Графік двоїстої функції}
\end{figure}

Табл. 3 мiстить характеристики апроксимацiї для рiвномiрно розподiленої сiтки. Як бачимо, зi збiльшенням кiлькостi елементiв, характеристики апроксимацiї покращуються.

\begin{table}[H]
\centering
\begin{tabular}{|l|l|l|l|l|l|l|l|}
\hline
N   & $ ||u_h||_V^2 $ & $ ||e_h||_V^2 $ & $ \frac{||e_h||_V}{||u_h||_V}, \% $ & $ p $ & $ ||\phi_h||^2 $ & $ ||f||^2 - ||u_h||^2 - ||\phi_h||^2 $ & $ \sqrt{\frac{||f||^2 - ||u_h||^2 - ||\phi_h||^2}{||u_h||^2 + ||\phi_h||^2}} \% $ \\ \hline
10 & 5.3966 & 0.030364 & 7.5011 &  & 63.155 & 5.3273 & 27.877 \\ \hline
20 & 5.4252 & 0.0076053 & 3.7441 & 1.0705 & 63.42 & 5.033 & 27.038 \\ \hline
40 & 5.4324 & 0.0019022 & 1.8713 & 1.0357 & 63.486 & 4.9605 & 26.828 \\ \hline
80 & 5.4342 & 0.00047561 & 0.93553 & 1.0179 & 63.503 & 4.941 & 26.772 \\ \hline
160 & 5.4347 & 0.00011891 & 0.46775 & 1.009 & 63.507 & 4.9367 & 26.759 \\ \hline

\end{tabular}
\caption{Характеристики апроксимацiї на рівномірній сiтцi.}
\end{table}

Табл. 4 мiстить характеристики апроксимацiї для адаптивної сiтки. Порядок збiжностi апроксимацiї свiдчить про те, що апроксимацiя швидко збiгається до свого точного розв’язку.

\begin{table}[H]
\centering
\begin{tabular}{|l|l|l|l|l|l|l|l|}
\hline
N   & $ ||u_h||_V^2 $ & $ ||e_h||_V^2 $ & $ \frac{||e_h||_V}{||u_h||_V}, \% $ & $ ||\phi_h||^2 $ & $ ||f||^2 - ||u_h||^2 - ||\phi_h||^2 $ & $ \sqrt{\frac{||f||^2 - ||u_h||^2 - ||\phi_h||^2}{||u_h||^2 + ||\phi_h||^2}} \% $ \\ \hline
2 & 4.5025 & 0.71243 & 39.778 & 54.946 & 14.43 & 49.267 \\ \hline
4 & 5.1971 & 0.18727 & 18.983 & 61.311 & 7.3705 & 33.29 \\ \hline
8 & 5.3751 & 0.047377 & 9.3884  & 62.956 & 5.5476 & 28.493 \\ \hline
14 & 5.4187 & 0.012501 & 4.8032 & 63.17 & 5.2901 & 27.772 \\ \hline
20 & 5.426 & 0.0065218 & 3.4669  & 63.178 & 5.2746 & 27.728 \\ \hline
22 & 5.4277 & 0.0051909 & 3.0925 & 63.188 & 5.2626 & 27.694 \\ \hline

\end{tabular}
\caption{Характеристики апроксимацiї на рівномірній сiтцi.}
\end{table}

\newpage
\section{Висновки}
Отже, побудовано $h$-адаптивну схему МСЕ для розв’язування лiнiйних крайових задач зi звичайни\-ми диференцiальними рiвняннями другого порядку. В основі МСЕ лежить проекційний метод Галь\-оркіна, з кусково-лінійними функціями Куранта в якості базису, побудований на нерівномірній сітці скінченних елементів. Доповнено системою локального згущення сітки на проблемних скінченних елементах з використанням апостеріорного оцінювача похибки на кожному елементі, незалежно від інших. Незначні обсяги обчислень досягаються вдалим вибором ортогонального базису простору апроксимацiї похибки, а саме
вибором - кусково-лiнiйної бабл функцiї на скiнченному елементi. Запропонована $h$-адаптивна схема продемонструвала ефективнiсть в обчислювальних експеримен\-тах.
\newpage
\begin{thebibliography}{9}
\bibitem{Abramov} 
Є.Абрамов, О.Лiпiна, Г.Шинкаренко, А.Ямелець 
\textit{КУСКОВО-ЛIНIЙНI АПРОКСИМАЦIЇ h-АДАПТИВНОГО МЕТОДУ СКIНЧЕННИХ ЕЛЕМЕНТIВ ДЛЯ ОДНОВИМIРНИХ КРАЙОВИХ ЗАДАЧ}. 
ЛНУ iм. Iвана Франка, Львiв, 2006.
 
\bibitem{Strang} 
G.Strang, G.Fix
\textit{An Analysis of the Finite Element Method}. 
Wellesley-Cambridge, Wellesley, 2nd edition, 2008.

 
\bibitem{github} 
Hans Petter Langtangen Website
\\\texttt{http://hplgit.github.io/INF5620/doc/pub/main\_fem.pdf}

\bibitem{python} 
Python Homepage
\\\texttt{https://www.python.org/}


\end{thebibliography}
\end{document}